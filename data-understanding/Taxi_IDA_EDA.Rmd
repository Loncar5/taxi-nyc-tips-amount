---
title: "Taxi - Tip Prediction Project"
output:
 github_document:
    number_sections: TRUE
    toc: TRUE
    fig_height: 6
    fig_width: 9
    code_folding: hide
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo=TRUE, error=FALSE)
```

#  Data Understanding and Data Preparation

## Load Libraries and Helper Functions 

```{r, message = FALSE, warning=FALSE, cached = TRUE}
library("Hmisc") # Descriptive Statistics
library("psych") # Descriptive Statistics
library('tidyverse') # ggplot2, dplyr, tidyr, readr, purrr, tibble
library('scales') # visualisation
library('grid') # visualisation
library('RColorBrewer') # visualisation
library('corrplot') # visualisation
library('alluvial') # visualisation
library('readr') # input/output
library('data.table') # data manipulation
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
library('lubridate') # date and time
library('xgboost') # modelling
library('caret') # modelling
# library('caTools')
# library('httpuv')
library("DT")
library("knitr")
```

```{r}
# Define multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}


# Normalize Function
normalize <- function(x) {
    return ((x - min(x)) / (max(x) - min(x)))
}

```

## Load The Data Sets {.tabset}

### Loading Taxi Main Data Set
```{r}
taxi_data <- "sample100000.csv"
taxi_data <- as.tibble(fread(taxi_data))

taxi_data <- taxi_data %>%
  mutate(date = date(pickup_datetime),
         wday = wday(pickup_datetime, label = TRUE),
         wday = fct_relevel(wday, c("Mon", "Tues", "Wed", "Thurs", "Fri", "Sat", "Sun")),
         hour = hour(pickup_datetime),
         work = (hour %in% seq(8,18)) & (wday %in% c("Mon","Tues","Wed","Thurs","Fri")),
         trip_duration = round(digits = 4, difftime(dropoff_datetime, pickup_datetime))) %>%
  arrange(pickup_datetime)
```

### Loading The Weather Data Set
```{r, warning = FALSE, message = FALSE, echo=TRUE, cached = TRUE}
weather <- "weather.csv"
weather <- as.tibble(fread(weather))

weather <- weather %>%
  select(DATE, TMAX,TMIN)

weather <- weather %>%
  mutate(date = date(DATE))

foo <- weather %>%
  select(date,TMAX, TMIN)

# rm(weather)

foo <- foo %>%
 filter(date > "2015-05-31" & date <"2015-07-1")
  
foo <- foo %>%
  head(30)
```

### Combining The Two Data Sets
```{r}
complete_dataset <- taxi_data %>%
  inner_join(foo, by = "date")
# rm(foo)
# rm(taxi_data)
```

## Data Set
```{r}
complete_dataset %>%
  head(25) %>%
  DT::datatable(options = list(pageLength=10, scrollX='400px'), filter = 'top')
```

## NA check?
```{r, cached = TRUE} 
any(is.na(complete_dataset)) #or
sum(is.na(complete_dataset))
```

## Data Types Check
```{r}
glimpse(complete_dataset)
```

## Changing Data Types Accordingly 
```{r}
complete_dataset <- complete_dataset %>%
  mutate(pickup_datetime = ymd_hms(pickup_datetime),
         dropoff_datetime = ymd_hms(dropoff_datetime),
         passenger_count = factor(passenger_count),
         pickup_borough = factor(pickup_borough),
         dropoff_borough = factor(dropoff_borough),
         pickup_neighborhood = factor(pickup_neighborhood),  
         dropoff_neighborhood = factor(dropoff_neighborhood),
         payment_type = factor(payment_type),
         extra = factor(extra),
         wday = factor(wday),
         work = factor(work),
         trip_duration = as.integer(trip_duration),
         TMAX = as.integer(TMAX),
         TMIN = as.integer(TMIN)) %>%
  select(-date)
```

## Error Identification Hunt 

## Data Split
```{r}
set.seed(4567)
indexes <- sample(1:nrow(complete_dataset), size=0.20*nrow(complete_dataset)) #Sample Indexes
# Split data
test <- complete_dataset[indexes,]
dim(test)  #  20000    19
train <- complete_dataset[-indexes,]
dim(train) # 80000    19

# Remove Target feature from the test set
# test$tip_amount <- NULL
# dim(test) # 25000    12
```


# Descriptive Statistics {.tabset}
Outliner Identification Hunt 

## By Proportions
```{r, cached = TRUE} 
# the package won't work with certain time data types, that's why we have to remove them, but not permanmently. It is just for the sake of descriptive statistics

descriptive_stat <- train %>%
  select(-c(pickup_datetime, dropoff_datetime))


Hmisc::describe(descriptive_stat) # :: selects particualr function from a library
```

## Granular look into the data

```{r, cached = TRUE} 
psych::describe(descriptive_stat) 
```